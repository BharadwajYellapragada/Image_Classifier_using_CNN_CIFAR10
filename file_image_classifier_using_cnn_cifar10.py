# -*- coding: utf-8 -*-
"""file_Image_Classifier_using_CNN_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HdqVFi1DPld0ZcK61knx1J6xHd38px85
"""

def load_cifar10_data():
  (training_image_data, training_label_data), (testing_image_data, testing_label_data) = tf.keras.datasets.cifar10.load_data()

def visualize_data():
  print("Number of images in training set are",training_image_data.shape[0],"with size",training_image_data[0].shape)
  print("Number of images in testing set are",testing_image_data.shape[0],"with size",training_image_data[0].shape)
  input_shape = training_image_data[0].shape
  count=0
  num_classes=10
  classes=['airplane','automobile','bird', 'cat', 'deer','dog', 'frog', 'horse','ship','truck'] 
  figure = plt.figure(figsize =(10,6))
  columns = 5
  rows = 2
  for i in range(len(training_label_data)):
    if int(training_label_data[i])==count:
      subplot(2,5,count+1)
      plt.title(str(count)+': '+classes[count])
      plt.imshow(training_image_data[i])
      plt.text(training_image_data[i].shape[0]/4,training_image_data[i].shape[1]+9,training_image_data[i].shape)
      count = count+1

def preprocess_data():
  trainY = to_categorical(training_label_data)
  testY = to_categorical(testing_label_data)
  # data = {training_label_data[i].tolist()[0]: trainY[i].tolist() for i in range(len(trainY))} 
  # print(pd.DataFrame(data=data.items(),columns=["label","one hot encoded"]))
  # convert from integers to floats
  normalized_training_image_data = training_image_data.astype('float32')
  normalized_testing_image_data = testing_image_data.astype('float32')
  # normalize to range 0-1
  normalized_training_image_data = normalized_training_image_data / 255.0
  normalized_testing_image_data = normalized_testing_image_data / 255.0

def load_model():
  model = Sequential()
  model.add(Convolution2D(4, 3, 3, border_mode='same', input_shape=input_shape))
  model.add(Activation('relu'))

  model.add(Convolution2D(6, 3, 3))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))

  model.add(BatchNormalization())

  model.add(Convolution2D(8, 3, 3, border_mode='same'))
  model.add(Activation('relu'))

  model.add(Convolution2D(16, 3, 3))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))

  model.add(BatchNormalization())
  # model.add(Convolution2D(192, 3, 3, border_mode='same'))
  # model.add(Activation('relu'))

  # model.add(Convolution2D(192, 3, 3))
  # model.add(Activation('relu'))
  # model.add(MaxPooling2D(pool_size=(2, 2)))
  # model.add(Dropout(0.25))

  model.add(Flatten())
  model.add(Dense(512))
  model.add(Activation('relu'))
  model.add(Dropout(0.5))
  model.add(Dense(256))
  model.add(Activation('relu'))
  model.add(Dropout(0.5))

  model.add(Dense(num_classes, activation='softmax'))

def compile_model():
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

def fit_model():
  # Train the model
  start = time.time()
  model_info = model.fit(normalized_training_image_data,trainY,batch_size=128, nb_epoch=200,validation_data = (normalized_testing_image_data, testY))
  end = time.time()

def plot_model_history(model_history):
    fig, axs = plt.subplots(1,2,figsize=(15,5))
    # summarize history for accuracy
    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])
    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])
    axs[0].set_title('Model Accuracy')
    axs[0].set_ylabel('Accuracy')
    axs[0].set_xlabel('Epoch')
    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)
    axs[0].legend(['train', 'val'], loc='best')
    # summarize history for loss
    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])
    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])
    axs[1].set_title('Model Loss')
    axs[1].set_ylabel('Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)
    axs[1].legend(['train', 'val'], loc='best')
    plt.show()

def accuracy(test_x, test_y, model):
    result = model.predict(test_x)
    predicted_class = np.argmax(result, axis=1)
    true_class = np.argmax(test_y, axis=1)
    num_correct = np.sum(predicted_class == true_class) 
    accuracy = float(num_correct)/result.shape[0]
    return (accuracy * 100)

def plot_results():
  plot_model_history(model_info)
  print("Model took %0.2f seconds to train"%(end - start))
  # compute test accuracy
  print("Accuracy on test data is: %0.2f"%accuracy(normalized_testing_image_data, testY, model))

if __name__ == "__main__":
  import tensorflow as tf
  import matplotlib.pyplot as plt
  from pylab import *
  from keras.utils import to_categorical
  from keras.models import Sequential
  from keras.layers.convolutional import Convolution2D, MaxPooling2D
  from keras.layers import Activation, Flatten, Dense, Dropout
  from keras.layers.normalization import BatchNormalization
  load_cifar10_data()
  visualize_data()
  preprocess_data()
  load_model()
  compile_model()
  fit_model()
  plot_results()